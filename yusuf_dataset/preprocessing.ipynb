{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "86959929",
      "metadata": {},
      "source": [
        "# Yusuf Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "70ec7964",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.12/site-packages (0.21.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: roboflow in /opt/anaconda3/lib/python3.12/site-packages (1.2.13)\n",
            "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (2024.6.2)\n",
            "Requirement already satisfied: idna==3.7 in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (3.8.4)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (12.1.0)\n",
            "Requirement already satisfied: pillow-avif-plugin<2 in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (1.5.5)\n",
            "Requirement already satisfied: python-dateutil in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (0.21.0)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (2.32.2)\n",
            "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (6.0.1)\n",
            "Requirement already satisfied: requests-toolbelt in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: pi-heif<2 in /opt/anaconda3/lib/python3.12/site-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->roboflow) (4.51.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->roboflow) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->roboflow) (3.0.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->roboflow) (2.0.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: imagehash in /opt/anaconda3/lib/python3.12/site-packages (4.3.2)\n",
            "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (12.1.0)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (4.66.4)\n",
            "Requirement already satisfied: PyWavelets in /opt/anaconda3/lib/python3.12/site-packages (from imagehash) (1.5.0)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from imagehash) (1.26.4)\n",
            "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from imagehash) (1.13.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install python-dotenv\n",
        "%pip install roboflow\n",
        "%pip install imagehash pillow tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0f1fb61d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in Food-Dataset-1 to yolov8:: 100%|██████████| 149379/149379 [00:07<00:00, 20031.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Food-Dataset-1 in yolov8:: 100%|██████████| 9832/9832 [00:01<00:00, 5100.76it/s]\n"
          ]
        }
      ],
      "source": [
        "# loads dataset\n",
        "from roboflow import Roboflow\n",
        "from dotenv import load_dotenv\n",
        "# from google.colab import userdata\n",
        "import os\n",
        "\n",
        "load_dotenv()  # loads variables from .env into the environment\n",
        "\n",
        "# os.environ[\"YF_API_KEY\"] = userdata.get(\"YF_API_KEY\")\n",
        "api_key = os.getenv(\"YF_API_KEY\")\n",
        "\n",
        "rf = Roboflow(api_key=api_key)\n",
        "project = rf.workspace(\"caretech\").project(\"food-dataset-uj20h-w2s4m\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1411519d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train images: 3917\n",
            "Train labels: 3917\n",
            "Val images: 982\n",
            "Val labels: 982\n",
            "Test images: 11\n",
            "Test labels: 11\n"
          ]
        }
      ],
      "source": [
        "# Sanity Check Dataset\n",
        "\n",
        "import os\n",
        "\n",
        "DATASET_PATH = dataset.location\n",
        "\n",
        "TRAIN_IMAGES = os.path.join(DATASET_PATH, \"train/images\")\n",
        "TRAIN_LABELS = os.path.join(DATASET_PATH, \"train/labels\")\n",
        "\n",
        "VAL_IMAGES = os.path.join(DATASET_PATH, \"valid/images\")\n",
        "VAL_LABELS = os.path.join(DATASET_PATH, \"valid/labels\")\n",
        "\n",
        "TEST_IMAGES = os.path.join(DATASET_PATH, \"test/images\")\n",
        "TEST_LABELS = os.path.join(DATASET_PATH, \"test/labels\")\n",
        "\n",
        "print(\"Train images:\", len(os.listdir(TRAIN_IMAGES)))\n",
        "print(\"Train labels:\", len(os.listdir(TRAIN_LABELS)))\n",
        "print(\"Val images:\", len(os.listdir(VAL_IMAGES)))\n",
        "print(\"Val labels:\", len(os.listdir(VAL_LABELS)))\n",
        "print(\"Test images:\", len(os.listdir(TEST_IMAGES)))\n",
        "print(\"Test labels:\", len(os.listdir(TEST_LABELS)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1d8fa5ee",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing labels in training set: 0\n"
          ]
        }
      ],
      "source": [
        "# Check for any missing labels\n",
        "import glob\n",
        "\n",
        "train_images = sorted(glob.glob(os.path.join(TRAIN_IMAGES, \"*\")))\n",
        "missing_labels = []\n",
        "\n",
        "for img_path in train_images:\n",
        "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    label_path = os.path.join(TRAIN_LABELS, base + \".txt\")\n",
        "    if not os.path.exists(label_path):\n",
        "        missing_labels.append(base)\n",
        "\n",
        "print(f\"Missing labels in training set: {len(missing_labels)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "47c2a364",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class_id</th>\n",
              "      <th>bbox_count</th>\n",
              "      <th>class_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>20</td>\n",
              "      <td>454</td>\n",
              "      <td>rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19</td>\n",
              "      <td>239</td>\n",
              "      <td>ramen-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3</td>\n",
              "      <td>188</td>\n",
              "      <td>beef-curry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>14</td>\n",
              "      <td>173</td>\n",
              "      <td>hamburger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>30</td>\n",
              "      <td>154</td>\n",
              "      <td>toast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>132</td>\n",
              "      <td>fried-rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>22</td>\n",
              "      <td>130</td>\n",
              "      <td>sandwiches</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>17</td>\n",
              "      <td>120</td>\n",
              "      <td>pork-cutlet-on-rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>25</td>\n",
              "      <td>119</td>\n",
              "      <td>sushi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>16</td>\n",
              "      <td>117</td>\n",
              "      <td>pizza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2</td>\n",
              "      <td>110</td>\n",
              "      <td>Orange</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>31</td>\n",
              "      <td>109</td>\n",
              "      <td>udon-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>107</td>\n",
              "      <td>beef-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>107</td>\n",
              "      <td>soba-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>24</td>\n",
              "      <td>106</td>\n",
              "      <td>spaghetti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>26</td>\n",
              "      <td>105</td>\n",
              "      <td>takoyaki</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>102</td>\n",
              "      <td>chip-butty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>27</td>\n",
              "      <td>100</td>\n",
              "      <td>tempura-bowl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>Japanese-style-pancake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>100</td>\n",
              "      <td>fried-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10</td>\n",
              "      <td>95</td>\n",
              "      <td>eels-on-rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>6</td>\n",
              "      <td>93</td>\n",
              "      <td>chicken-n-egg-on-rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>21</td>\n",
              "      <td>90</td>\n",
              "      <td>roll-bread</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>9</td>\n",
              "      <td>89</td>\n",
              "      <td>croissant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>15</td>\n",
              "      <td>87</td>\n",
              "      <td>pilaf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>28</td>\n",
              "      <td>85</td>\n",
              "      <td>tempura-udon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>29</td>\n",
              "      <td>84</td>\n",
              "      <td>tensin-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5</td>\n",
              "      <td>83</td>\n",
              "      <td>bibimbap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7</td>\n",
              "      <td>82</td>\n",
              "      <td>chicken-rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>80</td>\n",
              "      <td>raisin-bread</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>13</td>\n",
              "      <td>80</td>\n",
              "      <td>gratin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0</td>\n",
              "      <td>78</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    class_id  bbox_count              class_name\n",
              "12        20         454                    rice\n",
              "2         19         239            ramen-noodle\n",
              "19         3         188              beef-curry\n",
              "20        14         173               hamburger\n",
              "10        30         154                   toast\n",
              "0         12         132              fried-rice\n",
              "23        22         130              sandwiches\n",
              "25        17         120     pork-cutlet-on-rice\n",
              "17        25         119                   sushi\n",
              "18        16         117                   pizza\n",
              "30         2         110                  Orange\n",
              "13        31         109             udon-noodle\n",
              "7          4         107             beef-noodle\n",
              "22        23         107             soba-noodle\n",
              "28        24         106               spaghetti\n",
              "16        26         105                takoyaki\n",
              "3          8         102              chip-butty\n",
              "6         27         100            tempura-bowl\n",
              "27         1         100  Japanese-style-pancake\n",
              "4         11         100            fried-noodle\n",
              "11        10          95            eels-on-rice\n",
              "29         6          93   chicken-n-egg-on-rice\n",
              "26        21          90              roll-bread\n",
              "21         9          89               croissant\n",
              "5         15          87                   pilaf\n",
              "24        28          85            tempura-udon\n",
              "15        29          84           tensin-noodle\n",
              "8          5          83                bibimbap\n",
              "14         7          82            chicken-rice\n",
              "1         18          80            raisin-bread\n",
              "9         13          80                  gratin\n",
              "31         0          78                   Apple"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check Class Distribution\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import yaml\n",
        "\n",
        "# Load class names from data.yaml\n",
        "with open(os.path.join(DATASET_PATH, \"data.yaml\")) as f:\n",
        "    data_yaml = yaml.safe_load(f)\n",
        "\n",
        "class_names = data_yaml[\"names\"]\n",
        "\n",
        "label_dir = os.path.join(DATASET_PATH, \"train\", \"labels\")\n",
        "\n",
        "def plot_class_distribution(class_names, label_dir):\n",
        "    class_counts = Counter()\n",
        "\n",
        "    for label_file in glob.glob(os.path.join(label_dir, \"*.txt\")):\n",
        "        with open(label_file) as f:\n",
        "            for line in f:\n",
        "                class_id = int(line.split()[0])\n",
        "                class_counts[class_id] += 1\n",
        "\n",
        "    df_class_dist = pd.DataFrame(\n",
        "        [(k, v, class_names[k]) for k, v in class_counts.items()],\n",
        "        columns=[\"class_id\", \"bbox_count\", \"class_name\"]\n",
        "    ).sort_values(\"bbox_count\", ascending=False)\n",
        "\n",
        "    return df_class_dist\n",
        "\n",
        "df_class_dist = plot_class_distribution(class_names, label_dir)\n",
        "df_class_dist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6db84f0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "import imagehash\n",
        "from tqdm import tqdm\n",
        "\n",
        "def find_duplicate_images(image_dir, hash_size=8):\n",
        "    \"\"\"find duplicate images using perceptual hashing\"\"\"\n",
        "    hash_dict = defaultdict(list)\n",
        "    \n",
        "    # get all image files\n",
        "    image_extensions = ['*.jpg', '*.jpeg', '*.png']\n",
        "    image_paths = []\n",
        "    for ext in image_extensions:\n",
        "        image_paths.extend(glob.glob(os.path.join(image_dir, '**', ext), recursive=True))\n",
        "    \n",
        "    # remove any duplicates in the path list itself (shouldn't happen, but let's be safe)\n",
        "    image_paths = list(set(image_paths))\n",
        "    \n",
        "    print(f\"Found {len(image_paths)} images to process\")\n",
        "    \n",
        "    # hash all images\n",
        "    for img_path in tqdm(image_paths, desc=\"Calculating hashes\"):\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                img_hash = imagehash.phash(img.convert(\"RGB\"), hash_size=hash_size)\n",
        "                hash_dict[str(img_hash)].append(img_path)  # convert hash to string for dict key\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {e}\")\n",
        "    \n",
        "    # filter to only groups with duplicates\n",
        "    duplicates = {h: paths for h, paths in hash_dict.items() if len(paths) > 1}\n",
        "    \n",
        "    print(f\"\\nFound {len(duplicates)} duplicate groups\")\n",
        "    total_dups = sum(len(paths) - 1 for paths in duplicates.values())\n",
        "    print(f\"Total duplicate images: {total_dups}\")\n",
        "    \n",
        "    return duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9c3d02e5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4910 images to process\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating hashes: 100%|██████████| 4910/4910 [00:09<00:00, 533.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Found 157 duplicate groups\n",
            "Total duplicate images: 159\n",
            "\n",
            "Group 1: 2 duplicates (hash: 8eb5396a616a625b)\n",
            "  - 15002_jpg.rf.c3cf6e7b4c5f6291e920703a5d746955.jpg\n",
            "  - 14905_jpg.rf.d318089ed65a85e1e14f5269c1c942b0.jpg\n",
            "\n",
            "Group 2: 2 duplicates (hash: c02a037d7ee46bb1)\n",
            "  - 10710_jpg.rf.8e3cc1f882cdb9006c5cd70cb3918eab.jpg\n",
            "  - 9179_jpg.rf.bfe9f5f028f61ab41fb1a32e34fe95be.jpg\n",
            "\n",
            "Group 3: 2 duplicates (hash: c38f7c3972c76086)\n",
            "  - 9229_jpg.rf.70e3af1e15f620c4db00bbc5893d6583.jpg\n",
            "  - 10763_jpg.rf.7e50cf84fac15d60345f5a3fb8f8b9cc.jpg\n",
            "\n",
            "Group 4: 2 duplicates (hash: d42dd25589f215ce)\n",
            "  - 11082_jpg.rf.61c75eac95279575c3028f6fed4458b6.jpg\n",
            "  - 9330_jpg.rf.646bbcb95e169f57d691929f578da19e.jpg\n",
            "\n",
            "Group 5: 2 duplicates (hash: c2a995566a4ecd33)\n",
            "  - 11118_jpg.rf.f142d0f4a7dad7d5c08c5b41a18ecd11.jpg\n",
            "  - 9295_jpg.rf.d93ad7d3ad808b0da311c716d8a73847.jpg\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "duplicates = find_duplicate_images(DATASET_PATH)\n",
        "\n",
        "# display duplicate groups (showing different file paths)\n",
        "for i, (hash_val, paths) in enumerate(list(duplicates.items())[:5]):\n",
        "    print(f\"\\nGroup {i+1}: {len(paths)} duplicates (hash: {hash_val})\")\n",
        "    for p in paths[:5]:  # show first 5 paths per group\n",
        "        print(f\"  - {os.path.basename(p)}\")\n",
        "    if len(paths) > 5:\n",
        "        print(f\"  ... and {len(paths) - 5} more\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9678bdb7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed 159 duplicate images\n"
          ]
        }
      ],
      "source": [
        "def remove_duplicates(duplicates, keep='first'):\n",
        "    \"\"\"remove duplicates from dataset\"\"\"\n",
        "    removed = []\n",
        "    for hash_val, paths in duplicates.items():\n",
        "        # keep first image (or last), remove rest\n",
        "        to_remove = paths[1:] if keep == 'first' else paths[:-1]\n",
        "        for path in to_remove:\n",
        "            os.remove(path)\n",
        "            removed.append(path)\n",
        "            # remove associated label file if it exists\n",
        "            label_path = path.replace('/images/', '/labels/').rsplit('.', 1)[0] + '.txt'\n",
        "            if os.path.exists(label_path):\n",
        "                os.remove(label_path)\n",
        "\n",
        "    print(f\"Removed {len(removed)} duplicate images\")\n",
        "    return removed\n",
        "\n",
        "# remove duplicates\n",
        "removed = remove_duplicates(duplicates, keep='first')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e2305d5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4751 images to process\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating hashes: 100%|██████████| 4751/4751 [00:09<00:00, 506.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Found 0 duplicate groups\n",
            "Total duplicate images: 0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# double check duplicate images\n",
        "\n",
        "duplicates = find_duplicate_images(DATASET_PATH)\n",
        "\n",
        "# display duplicate groups (showing different file paths)\n",
        "for i, (hash_val, paths) in enumerate(list(duplicates.items())[:5]):\n",
        "    print(f\"\\nGroup {i+1}: {len(paths)} duplicates (hash: {hash_val})\")\n",
        "    for p in paths[:5]:  # show first 5 paths per group\n",
        "        print(f\"  - {os.path.basename(p)}\")\n",
        "    if len(paths) > 5:\n",
        "        print(f\"  ... and {len(paths) - 5} more\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "1e189c99",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class_id</th>\n",
              "      <th>bbox_count</th>\n",
              "      <th>class_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>20</td>\n",
              "      <td>454</td>\n",
              "      <td>rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19</td>\n",
              "      <td>239</td>\n",
              "      <td>ramen-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3</td>\n",
              "      <td>188</td>\n",
              "      <td>beef-curry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>14</td>\n",
              "      <td>173</td>\n",
              "      <td>hamburger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>30</td>\n",
              "      <td>154</td>\n",
              "      <td>toast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>132</td>\n",
              "      <td>fried-rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>22</td>\n",
              "      <td>130</td>\n",
              "      <td>sandwiches</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>17</td>\n",
              "      <td>120</td>\n",
              "      <td>pork-cutlet-on-rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>25</td>\n",
              "      <td>119</td>\n",
              "      <td>sushi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>16</td>\n",
              "      <td>117</td>\n",
              "      <td>pizza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2</td>\n",
              "      <td>110</td>\n",
              "      <td>Orange</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>31</td>\n",
              "      <td>109</td>\n",
              "      <td>udon-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>107</td>\n",
              "      <td>beef-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>107</td>\n",
              "      <td>soba-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>24</td>\n",
              "      <td>106</td>\n",
              "      <td>spaghetti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>26</td>\n",
              "      <td>105</td>\n",
              "      <td>takoyaki</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>102</td>\n",
              "      <td>chip-butty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>27</td>\n",
              "      <td>100</td>\n",
              "      <td>tempura-bowl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>Japanese-style-pancake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>100</td>\n",
              "      <td>fried-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10</td>\n",
              "      <td>95</td>\n",
              "      <td>eels-on-rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>6</td>\n",
              "      <td>93</td>\n",
              "      <td>chicken-n-egg-on-rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>21</td>\n",
              "      <td>90</td>\n",
              "      <td>roll-bread</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>9</td>\n",
              "      <td>89</td>\n",
              "      <td>croissant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>15</td>\n",
              "      <td>87</td>\n",
              "      <td>pilaf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>28</td>\n",
              "      <td>85</td>\n",
              "      <td>tempura-udon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>29</td>\n",
              "      <td>84</td>\n",
              "      <td>tensin-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5</td>\n",
              "      <td>83</td>\n",
              "      <td>bibimbap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7</td>\n",
              "      <td>82</td>\n",
              "      <td>chicken-rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>80</td>\n",
              "      <td>raisin-bread</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>13</td>\n",
              "      <td>80</td>\n",
              "      <td>gratin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0</td>\n",
              "      <td>78</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    class_id  bbox_count              class_name\n",
              "12        20         454                    rice\n",
              "2         19         239            ramen-noodle\n",
              "19         3         188              beef-curry\n",
              "20        14         173               hamburger\n",
              "10        30         154                   toast\n",
              "0         12         132              fried-rice\n",
              "23        22         130              sandwiches\n",
              "25        17         120     pork-cutlet-on-rice\n",
              "17        25         119                   sushi\n",
              "18        16         117                   pizza\n",
              "30         2         110                  Orange\n",
              "13        31         109             udon-noodle\n",
              "7          4         107             beef-noodle\n",
              "22        23         107             soba-noodle\n",
              "28        24         106               spaghetti\n",
              "16        26         105                takoyaki\n",
              "3          8         102              chip-butty\n",
              "6         27         100            tempura-bowl\n",
              "27         1         100  Japanese-style-pancake\n",
              "4         11         100            fried-noodle\n",
              "11        10          95            eels-on-rice\n",
              "29         6          93   chicken-n-egg-on-rice\n",
              "26        21          90              roll-bread\n",
              "21         9          89               croissant\n",
              "5         15          87                   pilaf\n",
              "24        28          85            tempura-udon\n",
              "15        29          84           tensin-noodle\n",
              "8          5          83                bibimbap\n",
              "14         7          82            chicken-rice\n",
              "1         18          80            raisin-bread\n",
              "9         13          80                  gratin\n",
              "31         0          78                   Apple"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find class distribution\n",
        "df_class_dist = plot_class_distribution(class_names, label_dir)\n",
        "df_class_dist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "8e2b952a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rice count: 454\n",
            "Second highest: 239\n",
            "Undersampling ratio: 1.90\n"
          ]
        }
      ],
      "source": [
        "# undersampling logic\n",
        "\n",
        "# get rice class count and second highest\n",
        "rice_count = df_class_dist[df_class_dist['class_name'] == 'rice']['bbox_count'].values[0]\n",
        "second_highest = df_class_dist[df_class_dist['class_name'] != 'rice']['bbox_count'].nlargest(2).values[0]\n",
        "\n",
        "# calculate undersampling ratio\n",
        "ratio = rice_count / second_highest\n",
        "\n",
        "print(f\"Rice count: {rice_count}\")\n",
        "print(f\"Second highest: {second_highest}\")\n",
        "print(f\"Undersampling ratio: {ratio:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "d11a402f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target rice count: 298\n",
            "Rice annotations to remove: 156\n",
            "Images containing rice: 454\n",
            "Will remove 156 images (156 rice annotations)\n"
          ]
        }
      ],
      "source": [
        "# undersample rice class to TARGET_RATIO of second highest class\n",
        "TARGET_RATIO = 1.25  # adjust between 1.0 and 1.5 as needed\n",
        "\n",
        "rice_class_id = class_names.index(\"rice\")\n",
        "target_rice_count = int(second_highest * TARGET_RATIO)\n",
        "annotations_to_remove = rice_count - target_rice_count\n",
        "\n",
        "print(f\"Target rice count: {target_rice_count}\")\n",
        "print(f\"Rice annotations to remove: {annotations_to_remove}\")\n",
        "\n",
        "# find images containing rice and count rice annotations per image\n",
        "rice_images = {}  # {base_name: rice_annotation_count}\n",
        "for label_file in glob.glob(os.path.join(TRAIN_LABELS, \"*.txt\")):\n",
        "    base = os.path.splitext(os.path.basename(label_file))[0]\n",
        "    with open(label_file) as f:\n",
        "        rice_count_in_file = sum(1 for line in f if int(line.split()[0]) == rice_class_id)\n",
        "    if rice_count_in_file > 0:\n",
        "        rice_images[base] = rice_count_in_file\n",
        "\n",
        "print(f\"Images containing rice: {len(rice_images)}\")\n",
        "\n",
        "# select images to remove (prioritize images with more rice annotations)\n",
        "sorted_by_rice = sorted(rice_images.items(), key=lambda x: -x[1])\n",
        "images_to_remove = []\n",
        "removed_annotations = 0\n",
        "\n",
        "for base, count in sorted_by_rice:\n",
        "    if removed_annotations >= annotations_to_remove:\n",
        "        break\n",
        "    images_to_remove.append(base)\n",
        "    removed_annotations += count\n",
        "\n",
        "print(f\"Will remove {len(images_to_remove)} images ({removed_annotations} rice annotations)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "139e9513",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Removing rice images: 100%|██████████| 156/156 [00:00<00:00, 1843.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed 156 images and labels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# execute undersampling - remove selected images and labels\n",
        "removed_count = 0\n",
        "for base in tqdm(images_to_remove, desc=\"Removing rice images\"):\n",
        "    # remove image file\n",
        "    for ext in ['.jpg', '.jpeg', '.png']:\n",
        "        img_path = os.path.join(TRAIN_IMAGES, base + ext)\n",
        "        if os.path.exists(img_path):\n",
        "            os.remove(img_path)\n",
        "            break\n",
        "    # remove label file\n",
        "    label_path = os.path.join(TRAIN_LABELS, base + \".txt\")\n",
        "    if os.path.exists(label_path):\n",
        "        os.remove(label_path)\n",
        "    removed_count += 1\n",
        "\n",
        "print(f\"Removed {removed_count} images and labels\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "4ed95d71",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New rice count: 298\n",
            "Second highest: 239\n",
            "New ratio: 1.25x\n",
            "\n",
            "New class distribution:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class_id</th>\n",
              "      <th>bbox_count</th>\n",
              "      <th>class_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>20</td>\n",
              "      <td>298</td>\n",
              "      <td>rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19</td>\n",
              "      <td>239</td>\n",
              "      <td>ramen-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3</td>\n",
              "      <td>188</td>\n",
              "      <td>beef-curry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>14</td>\n",
              "      <td>173</td>\n",
              "      <td>hamburger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>30</td>\n",
              "      <td>154</td>\n",
              "      <td>toast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>132</td>\n",
              "      <td>fried-rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>130</td>\n",
              "      <td>sandwiches</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>17</td>\n",
              "      <td>120</td>\n",
              "      <td>pork-cutlet-on-rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>25</td>\n",
              "      <td>119</td>\n",
              "      <td>sushi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>16</td>\n",
              "      <td>117</td>\n",
              "      <td>pizza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2</td>\n",
              "      <td>110</td>\n",
              "      <td>Orange</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>31</td>\n",
              "      <td>109</td>\n",
              "      <td>udon-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>23</td>\n",
              "      <td>107</td>\n",
              "      <td>soba-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>107</td>\n",
              "      <td>beef-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>24</td>\n",
              "      <td>106</td>\n",
              "      <td>spaghetti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>26</td>\n",
              "      <td>105</td>\n",
              "      <td>takoyaki</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>102</td>\n",
              "      <td>chip-butty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>100</td>\n",
              "      <td>fried-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>Japanese-style-pancake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>27</td>\n",
              "      <td>100</td>\n",
              "      <td>tempura-bowl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10</td>\n",
              "      <td>95</td>\n",
              "      <td>eels-on-rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>6</td>\n",
              "      <td>93</td>\n",
              "      <td>chicken-n-egg-on-rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>21</td>\n",
              "      <td>90</td>\n",
              "      <td>roll-bread</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>9</td>\n",
              "      <td>89</td>\n",
              "      <td>croissant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>15</td>\n",
              "      <td>87</td>\n",
              "      <td>pilaf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>28</td>\n",
              "      <td>85</td>\n",
              "      <td>tempura-udon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>29</td>\n",
              "      <td>84</td>\n",
              "      <td>tensin-noodle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5</td>\n",
              "      <td>83</td>\n",
              "      <td>bibimbap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>7</td>\n",
              "      <td>82</td>\n",
              "      <td>chicken-rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>80</td>\n",
              "      <td>raisin-bread</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>13</td>\n",
              "      <td>80</td>\n",
              "      <td>gratin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0</td>\n",
              "      <td>78</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    class_id  bbox_count              class_name\n",
              "31        20         298                    rice\n",
              "2         19         239            ramen-noodle\n",
              "18         3         188              beef-curry\n",
              "19        14         173               hamburger\n",
              "10        30         154                   toast\n",
              "0         12         132              fried-rice\n",
              "22        22         130              sandwiches\n",
              "24        17         120     pork-cutlet-on-rice\n",
              "16        25         119                   sushi\n",
              "17        16         117                   pizza\n",
              "29         2         110                  Orange\n",
              "12        31         109             udon-noodle\n",
              "21        23         107             soba-noodle\n",
              "7          4         107             beef-noodle\n",
              "27        24         106               spaghetti\n",
              "15        26         105                takoyaki\n",
              "3          8         102              chip-butty\n",
              "4         11         100            fried-noodle\n",
              "26         1         100  Japanese-style-pancake\n",
              "6         27         100            tempura-bowl\n",
              "11        10          95            eels-on-rice\n",
              "28         6          93   chicken-n-egg-on-rice\n",
              "25        21          90              roll-bread\n",
              "20         9          89               croissant\n",
              "5         15          87                   pilaf\n",
              "23        28          85            tempura-udon\n",
              "14        29          84           tensin-noodle\n",
              "8          5          83                bibimbap\n",
              "13         7          82            chicken-rice\n",
              "1         18          80            raisin-bread\n",
              "9         13          80                  gratin\n",
              "30         0          78                   Apple"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# verify new class distribution\n",
        "df_new_dist = plot_class_distribution(class_names, TRAIN_LABELS)\n",
        "new_rice = df_new_dist[df_new_dist['class_name'] == 'rice']['bbox_count'].values[0]\n",
        "new_second = df_new_dist[df_new_dist['class_name'] != 'rice']['bbox_count'].max()\n",
        "\n",
        "print(f\"New rice count: {new_rice}\")\n",
        "print(f\"Second highest: {new_second}\")\n",
        "print(f\"New ratio: {new_rice / new_second:.2f}x\")\n",
        "print(f\"\\nNew class distribution:\")\n",
        "df_new_dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "352a1f09",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After undersampling:\n",
            "Train images: 3629\n",
            "Train labels: 3629\n"
          ]
        }
      ],
      "source": [
        "# sanity check - verify image/label counts after undersampling\n",
        "print(\"After undersampling:\")\n",
        "print(f\"Train images: {len(os.listdir(TRAIN_IMAGES))}\")\n",
        "print(f\"Train labels: {len(os.listdir(TRAIN_LABELS))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "004d9173",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
